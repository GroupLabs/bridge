{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do list\n",
    "- switch to storage\n",
    "- ingest csvs like storage class\n",
    "- figure out traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/noelthomas/Documents/GitHub/Bridge/src/lakehouse/adding_data_to_storage.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/src/lakehouse/adding_data_to_storage.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdotenv\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dotenv, find_dotenv\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/src/lakehouse/adding_data_to_storage.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/src/lakehouse/adding_data_to_storage.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m Storage \u001b[39mas\u001b[39;00m s\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import graph as g\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from .storage import Storage as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/datasets/football/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = s.Storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.graph.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = [data_path + item for item in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/datasets/football/teams.csv',\n",
       " '../../data/datasets/football/appearances.csv',\n",
       " '../../data/datasets/football/shots.desc',\n",
       " '../../data/datasets/football/appearances.desc',\n",
       " '../../data/datasets/football/leagues.desc',\n",
       " '../../data/datasets/football/players.desc',\n",
       " '../../data/datasets/football/games.desc',\n",
       " '../../data/datasets/football/teamstats.csv',\n",
       " '../../data/datasets/football/leagues.csv',\n",
       " '../../data/datasets/football/players.csv',\n",
       " '../../data/datasets/football/games.csv',\n",
       " '../../data/datasets/football/teams.desc',\n",
       " '../../data/datasets/football/shots.csv',\n",
       " '../../data/datasets/football/teamstats.desc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in result_list if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.store(csv_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph: \n",
       "Vector Storage: \n",
       ".... storing 1 value(s)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/datasets/football/teams.csv',\n",
       " '../../data/datasets/football/appearances.csv',\n",
       " '../../data/datasets/football/teamstats.csv',\n",
       " '../../data/datasets/football/leagues.csv',\n",
       " '../../data/datasets/football/players.csv',\n",
       " '../../data/datasets/football/games.csv',\n",
       " '../../data/datasets/football/shots.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.store_list(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ../../data/datasets/football/shots.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/appearances.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/leagues.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/players.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/games.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/teams.desc as it's a description file\n",
      "Skipping ../../data/datasets/football/teamstats.desc as it's a description file\n"
     ]
    }
   ],
   "source": [
    "storage.create_relationships_structured(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "rt = storage.vec_store.query(\"How many appearances did each player have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 0: Name is appearances\n",
      "Dictionary 1: Name is players\n",
      "Dictionary 2: Name is teamstats\n"
     ]
    }
   ],
   "source": [
    "for index, dictionary in enumerate(rt):\n",
    "    # Use dict.get() to safely get the value of the 'name' key if it exists,\n",
    "    # or None if it doesn't exist\n",
    "    name_value = dictionary.get('name')\n",
    "    \n",
    "    if name_value is not None:\n",
    "        print(f'Dictionary {index}: Name is {name_value}')\n",
    "    else:\n",
    "        print(f'Dictionary {index} does not have a \"name\" key.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path0': ['games.leagueID = appearances.leagueID',\n",
       "  'appearances.playerID = players.playerID'],\n",
       " 'path1': ['games.gameID = appearances.gameID',\n",
       "  'appearances.playerID = players.playerID']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.graph.node_traversal(\"games\" , \"players\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path0': ['appearances.playerID = players.playerID']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.query(\"How many appearances did each player have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STOP\n",
    "\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(storage.graph.node_traversal(\"games\" , \"players\", 3)[0][0][0].end_node)\n",
    "storage.graph.node_traversal(\"games\" , \"players\", 3)[0][0][0].start_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, summary, path = storage.graph.node_traversal(\"games\" , \"players\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = results[0].value(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation1, relation2, relation3 = Path.relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation1.get(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation3.get(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation2.get(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relationship in relationships:\n",
    "    relationship_properties = relationship.properties\n",
    "    print(\"Relationship properties:\", relationship_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = path.relationships\n",
    "\n",
    "# Iterate through the relationships\n",
    "for relationship in relationships:\n",
    "    # Access relationship properties\n",
    "    relationship_properties = relationship.properties\n",
    "    print(\"Relationship properties:\", relationship_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.graph.node_traversal(\"games\" , \"players\", 3)[0][0][0].relationships[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.graph.node_traversal(\"games\" , \"players\", 3)[0][0][0].relationships[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = g.Graph(os.getenv('GRAPH_URI'), os.getenv('GRAPH_USER') , os.getenv('GRAPH_PASS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = s.metadata(\"../../dev/data/Football Example/\" + csv_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = metadata(\"../../dev/data/Football Example/\" + csv_files[0])\n",
    "# \"../../dev/data/Football Example/apperances.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull all test CSVs\n",
    "- pull all test dfs into a dict/hash map, pull their columns\n",
    "- pull their PK/FK pairs\n",
    "  - all PKs are first column\n",
    "  - check to see if FK appears in column list\n",
    "  - write another check to find all PK/FKs in dataframes based on keywords ('ID', 'KEY')\n",
    "    - check across all dataframes for matching keys\n",
    "\n",
    "- example\n",
    "  - dataframe w/ GameID\n",
    "  - dataframe w/ PlayerID\n",
    "  - dataframe w/ GameID, PlayerID, etc\n",
    "    - this would be composite key if multiple IDs\n",
    "  - dataframe w/ GameID (FK), PlayerID (FK), EventID (PK)\n",
    "    - has one PK, how would we identify?\n",
    "    - would it be same as node name + id/key?\n",
    "- non-automated example\n",
    "  - make a file that makes PK/FK pairs w/ table names\n",
    "    - relationships.txt\n",
    "    - relationships.json\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(\"../../dev/data/Football Example/\" + f, encoding='latin-1')\n",
    "    df_name = f.split(\"\\\\\")[-1].split('.csv')[0]\n",
    "    df_keys = []\n",
    "    for column in df.columns.tolist():\n",
    "        if (\"id\") in column.lower():\n",
    "            df_keys.append(column)\n",
    "            \n",
    "    df_dict[df_name] = {\"columns\" : df.columns.tolist(),\n",
    "                        \"keys\": df_keys}\n",
    "                        \n",
    "      \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1].split('.csv')[0])\n",
    "      \n",
    "    # print the content\n",
    "    # print('Content:')\n",
    "    # display(df)\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict.get(\"appearances\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Data Frames into Nodes\n",
    "- assuming after turning all file types/databases into pandas dataframes we can turn them into nodes\n",
    "  - also assuming we might not even have to pull full DFs, just metadata, columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dict in df_dict.items():\n",
    "    print(name, dict.get(\"keys\"))\n",
    "    keys = dict.get(\"keys\")\n",
    "    print(name, dict.get(\"columns\"))\n",
    "    columns = dict.get(\"columns\")\n",
    "    print(\"Creating node!!!\")\n",
    "    graph.add_table_node(name, dict.get(\"keys\"), dict.get(\"columns\"), \"TABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_relationships = []\n",
    "for table1, dict1 in df_dict.items():\n",
    "    keys1 = dict1.get(\"keys\")\n",
    "    for table2, dict2 in df_dict.items():\n",
    "        keys2 = dict2.get(\"keys\")\n",
    "        if table1 != table2:\n",
    "            shared_keys = list(set(keys1) & set(keys2))\n",
    "            if shared_keys:\n",
    "                for i, shared_key in enumerate(shared_keys, start = 1):\n",
    "                    table_relationships.append((table1, table2, f\"{table1}.{shared_key} = {table2}.{shared_key}\", i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These relationships weren't recognized, as shooterID and assisterID doesn't explicely say person, bet contextually we know shooters and assisters are people\n",
    "table1, table2 = 'shots', 'players'\n",
    "table_relationships.append((table1, table2, f\"{table1}.shooterID = {table2}.playerID\", i)) \n",
    "table_relationships.append((table1, table2, f\"{table1}.assisterID = {table2}.playerID\", i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relationship in table_relationships:\n",
    "    node_one = relationship[0]\n",
    "    node_two = relationship[1] \n",
    "    key = f\"\"\"JOIN {{key : \"{relationship[2]}\"}}\"\"\"\n",
    "    # print(node_one, node_two, key)\n",
    "    graph.add_relationship(name_node_one= node_one, name_node_two= node_two, relation_name= key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
