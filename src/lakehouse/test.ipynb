{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do list\n",
    "- switch to storage\n",
    "- ingest csvs like storage class\n",
    "- figure out traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knowledge_graph as g\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from storage import Metadata, Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = g.Graph(os.getenv('GRAPH_URI'), os.getenv('GRAPH_USER') , os.getenv('GRAPH_PASS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = os.listdir(\"../../dev/data/Football Example/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appearances.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../dev/data/Football Example/appearances.desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2268f5d1d124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../dev/data/Football Example/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;34m\"../../dev/data/Football Example/apperances.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\benro\\Documents\\GitHub\\Bridge\\src\\lakehouse\\storage.py\u001b[0m in \u001b[0;36mmetadata\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;31m# get description from desc file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name}.desc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../dev/data/Football Example/appearances.desc'"
     ]
    }
   ],
   "source": [
    "# m = metadata(\"../../dev/data/Football Example/\" + csv_files[0])\n",
    "# \"../../dev/data/Football Example/apperances.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull all test CSVs\n",
    "- pull all test dfs into a dict/hash map, pull their columns\n",
    "- pull their PK/FK pairs\n",
    "  - all PKs are first column\n",
    "  - check to see if FK appears in column list\n",
    "  - write another check to find all PK/FKs in dataframes based on keywords ('ID', 'KEY')\n",
    "    - check across all dataframes for matching keys\n",
    "\n",
    "- example\n",
    "  - dataframe w/ GameID\n",
    "  - dataframe w/ PlayerID\n",
    "  - dataframe w/ GameID, PlayerID, etc\n",
    "    - this would be composite key if multiple IDs\n",
    "  - dataframe w/ GameID (FK), PlayerID (FK), EventID (PK)\n",
    "    - has one PK, how would we identify?\n",
    "    - would it be same as node name + id/key?\n",
    "- non-automated example\n",
    "  - make a file that makes PK/FK pairs w/ table names\n",
    "    - relationships.txt\n",
    "    - relationships.json\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: appearances.csv\n",
      "File Name: appearances\n",
      "Location: games.csv\n",
      "File Name: games\n",
      "Location: leagues.csv\n",
      "File Name: leagues\n",
      "Location: players.csv\n",
      "File Name: players\n",
      "Location: shots.csv\n",
      "File Name: shots\n",
      "Location: teams.csv\n",
      "File Name: teams\n",
      "Location: teamstats.csv\n",
      "File Name: teamstats\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(\"../../dev/data/Football Example/\" + f, encoding='latin-1')\n",
    "    df_name = f.split(\"\\\\\")[-1].split('.csv')[0]\n",
    "    df_keys = []\n",
    "    for column in df.columns.tolist():\n",
    "        if (\"id\") in column.lower():\n",
    "            df_keys.append(column)\n",
    "            \n",
    "    df_dict[df_name] = {\"columns\" : df.columns.tolist(),\n",
    "                        \"keys\": df_keys}\n",
    "                        \n",
    "      \n",
    "    # print the location and filename\n",
    "    print('Location:', f)\n",
    "    print('File Name:', f.split(\"\\\\\")[-1].split('.csv')[0])\n",
    "      \n",
    "    # print the content\n",
    "    # print('Content:')\n",
    "    # display(df)\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Data Frames into Nodes\n",
    "- assuming after turning all file types/databases into pandas dataframes we can turn them into nodes\n",
    "  - also assuming we might not even have to pull full DFs, just metadata, columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('appearances', {'columns': ['gameID', 'playerID', 'goals', 'ownGoals', 'shots', 'xGoals', 'xGoalsChain', 'xGoalsBuildup', 'assists', 'keyPasses', 'xAssists', 'position', 'positionOrder', 'yellowCard', 'redCard', 'time', 'substituteIn', 'substituteOut', 'leagueID'], 'keys': ['gameID', 'playerID', 'leagueID']}), ('games', {'columns': ['gameID', 'leagueID', 'season', 'date', 'homeTeamID', 'awayTeamID', 'homeGoals', 'awayGoals', 'homeProbability', 'drawProbability', 'awayProbability', 'homeGoalsHalfTime', 'awayGoalsHalfTime', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'PSCH', 'PSCD', 'PSCA'], 'keys': ['gameID', 'leagueID', 'homeTeamID', 'awayTeamID']}), ('leagues', {'columns': ['leagueID', 'name', 'understatNotation'], 'keys': ['leagueID']}), ('players', {'columns': ['playerID', 'name'], 'keys': ['playerID']}), ('shots', {'columns': ['gameID', 'shooterID', 'assisterID', 'minute', 'situation', 'lastAction', 'shotType', 'shotResult', 'xGoal', 'positionX', 'positionY'], 'keys': ['gameID', 'shooterID', 'assisterID']}), ('teams', {'columns': ['teamID', 'name'], 'keys': ['teamID']}), ('teamstats', {'columns': ['gameID', 'teamID', 'season', 'date', 'location', 'goals', 'xGoals', 'shots', 'shotsOnTarget', 'deep', 'ppda', 'fouls', 'corners', 'yellowCards', 'redCards', 'result'], 'keys': ['gameID', 'teamID']})])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appearances ['gameID', 'playerID', 'leagueID']\n",
      "appearances ['gameID', 'playerID', 'goals', 'ownGoals', 'shots', 'xGoals', 'xGoalsChain', 'xGoalsBuildup', 'assists', 'keyPasses', 'xAssists', 'position', 'positionOrder', 'yellowCard', 'redCard', 'time', 'substituteIn', 'substituteOut', 'leagueID']\n",
      "Creating node!!!\n",
      "games ['gameID', 'leagueID', 'homeTeamID', 'awayTeamID']\n",
      "games ['gameID', 'leagueID', 'season', 'date', 'homeTeamID', 'awayTeamID', 'homeGoals', 'awayGoals', 'homeProbability', 'drawProbability', 'awayProbability', 'homeGoalsHalfTime', 'awayGoalsHalfTime', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'PSCH', 'PSCD', 'PSCA']\n",
      "Creating node!!!\n",
      "leagues ['leagueID']\n",
      "leagues ['leagueID', 'name', 'understatNotation']\n",
      "Creating node!!!\n",
      "players ['playerID']\n",
      "players ['playerID', 'name']\n",
      "Creating node!!!\n",
      "shots ['gameID', 'shooterID', 'assisterID']\n",
      "shots ['gameID', 'shooterID', 'assisterID', 'minute', 'situation', 'lastAction', 'shotType', 'shotResult', 'xGoal', 'positionX', 'positionY']\n",
      "Creating node!!!\n",
      "teams ['teamID']\n",
      "teams ['teamID', 'name']\n",
      "Creating node!!!\n",
      "teamstats ['gameID', 'teamID']\n",
      "teamstats ['gameID', 'teamID', 'season', 'date', 'location', 'goals', 'xGoals', 'shots', 'shotsOnTarget', 'deep', 'ppda', 'fouls', 'corners', 'yellowCards', 'redCards', 'result']\n",
      "Creating node!!!\n"
     ]
    }
   ],
   "source": [
    "for name, dict in df_dict.items():\n",
    "    print(name, dict.get(\"keys\"))\n",
    "    keys = dict.get(\"keys\")\n",
    "    print(name, dict.get(\"columns\"))\n",
    "    columns = dict.get(\"columns\")\n",
    "    print(\"Creating node!!!\")\n",
    "    graph.add_table_node(name, dict.get(\"keys\"), dict.get(\"columns\"), \"TABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table1, keys1 in table_primary_keys.items():\n",
    "    for table2, keys2 in table_primary_keys.items():\n",
    "        # Avoid comparing a table to itself\n",
    "        if table1 != table2:\n",
    "            # Check if there are shared primary keys\n",
    "            shared_keys = set(keys1) & set(keys2)\n",
    "            if shared_keys:\n",
    "                # Append the relationship to the list\n",
    "                table_relationships.append((table1, table2, shared_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_relationships = []\n",
    "for table1, dict1 in df_dict.items():\n",
    "    keys1 = dict1.get(\"keys\")\n",
    "    for table2, dict2 in df_dict.items():\n",
    "        keys2 = dict2.get(\"keys\")\n",
    "        if table1 != table2:\n",
    "            shared_keys = set(keys1) & set(keys2)\n",
    "            if shared_keys:\n",
    "                for shared_key in shared_keys:\n",
    "                    table_relationships.append((table1, table2, shared_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gameID', 'leagueID'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_relationships[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('appearances', 'games', {'gameID', 'leagueID'}),\n",
       " ('appearances', 'leagues', {'leagueID'}),\n",
       " ('appearances', 'players', {'playerID'}),\n",
       " ('appearances', 'shots', {'gameID'}),\n",
       " ('appearances', 'teamstats', {'gameID'}),\n",
       " ('games', 'appearances', {'gameID', 'leagueID'}),\n",
       " ('games', 'leagues', {'leagueID'}),\n",
       " ('games', 'shots', {'gameID'}),\n",
       " ('games', 'teamstats', {'gameID'}),\n",
       " ('leagues', 'appearances', {'leagueID'}),\n",
       " ('leagues', 'games', {'leagueID'}),\n",
       " ('players', 'appearances', {'playerID'}),\n",
       " ('shots', 'appearances', {'gameID'}),\n",
       " ('shots', 'games', {'gameID'}),\n",
       " ('shots', 'teamstats', {'gameID'}),\n",
       " ('teams', 'teamstats', {'teamID'}),\n",
       " ('teamstats', 'appearances', {'gameID'}),\n",
       " ('teamstats', 'games', {'gameID'}),\n",
       " ('teamstats', 'shots', {'gameID'}),\n",
       " ('teamstats', 'teams', {'teamID'})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
