{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is designed to trace PyTorch models\n",
    "\n",
    "### Defining the appropriate classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.regressor = nn.Linear(self.bert.config.dim, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        out = self.regressor(outputs[0][:, 0, :])\n",
    "        return torch.squeeze(out, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distil_v1_friendly\"\n",
    "version = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"model_checkpoints/torch/{model_name}.pt\"  # Replace with your .pt file path\n",
    "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = BertRegressor(bert_model)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process & inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_padding(input_tensor):\n",
    "    last_non_padding = torch.nonzero(input_tensor[0]).squeeze(-1)[-1].item() + 1\n",
    "    return input_tensor[:, :last_non_padding]\n",
    "\n",
    "def preprocess(text, remove_padding=True):\n",
    "    max_len = 512 # maybe need to make this dynamic\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    # pre-process text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    if remove_padding:\n",
    "        input_ids = _remove_padding(input_ids)\n",
    "        attention_mask = _remove_padding(attention_mask)\n",
    "    \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_model(input_ids, attention_mask):\n",
    "    \n",
    "    traced_model = torch.jit.trace(model, (input_ids, attention_mask))\n",
    "    \n",
    "    return traced_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, am = preprocess(\"I love machine learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript = trace_model(i, am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: model_repository/distil_v1_friendly/1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def ensure_path_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Path created: {path}\")\n",
    "    else:\n",
    "        print(f\"Path already exists: {path}\")\n",
    "\n",
    "ensure_path_exists(f\"model_repository/{model_name}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the traced model\n",
    "torchscript.save(f\"model_repository/{model_name}/{version}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate config\n",
    "\n",
    "config = f\"\"\"name: \"{model_name}\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 1\n",
    "input [\n",
    "  {{\n",
    "    name: \"input_ids\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  }},\n",
    "  {{\n",
    "    name: \"attention_mask\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }}\n",
    "]\n",
    "output [\n",
    "  {{\n",
    "    name: \"output\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "  }}\n",
    "]\n",
    "optimization {{\n",
    "  execution_accelerators {{\n",
    "    cpu_execution_accelerator : [{{\n",
    "      name : \"openvino\"\n",
    "    }}]\n",
    "  }}\n",
    "}}\n",
    "parameters: {{\n",
    "key: \"INFERENCE_MODE\"\n",
    "    value: {{\n",
    "    string_value: \"true\"\n",
    "    }}\n",
    "}}\n",
    "instance_group [\n",
    "  {{\n",
    "    count: 1\n",
    "    kind: KIND_CPU\n",
    "  }}\n",
    "]\"\"\"\n",
    "\n",
    "with open(f\"model_repository/{model_name}/config.pbtxt\", 'w') as file:\n",
    "    file.write(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
