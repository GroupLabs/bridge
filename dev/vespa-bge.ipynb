{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install FlagEmbedding -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelthomas/Documents/GitHub/Bridge/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 22 files: 100%|██████████| 22/22 [00:00<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing colbert_linear and sparse_linear---------\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_embeddings = model.encode(passage, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import Schema, Document, Field, FieldSet\n",
    "m_schema = Schema(\n",
    "            name=\"m\",\n",
    "            document=Document(\n",
    "                fields=[\n",
    "                    Field(name=\"id\", type=\"string\", indexing=[\"summary\"]),\n",
    "                    Field(name=\"text\", type=\"string\", indexing=[\"summary\", \"index\"], index=\"enable-bm25\"),\n",
    "                    Field(name=\"lexical_rep\", type=\"tensor<bfloat16>(t{})\", indexing=[\"summary\", \"attribute\"]),\n",
    "                    Field(name=\"dense_rep\", type=\"tensor<bfloat16>(x[1024])\", indexing=[\"summary\", \"attribute\"], attribute=[\"distance-metric: angular\"]),\n",
    "                    Field(name=\"colbert_rep\", type=\"tensor<bfloat16>(t{}, x[1024])\", indexing=[\"summary\", \"attribute\"])\n",
    "                ],\n",
    "            ),\n",
    "            fieldsets=[\n",
    "                FieldSet(name = \"default\", fields = [\"text\"])\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage\n",
    "\n",
    "vespa_app_name = \"mtest\"\n",
    "vespa_application_package = ApplicationPackage(\n",
    "        name=vespa_app_name,\n",
    "        schema=[m_schema]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import RankProfile, Function,  FirstPhaseRanking\n",
    "\n",
    "\n",
    "semantic = RankProfile(\n",
    "    name=\"m3hybrid\", \n",
    "    inputs=[\n",
    "        (\"query(q_dense)\", \"tensor<bfloat16>(x[1024])\"), \n",
    "        (\"query(q_lexical)\", \"tensor<bfloat16>(t{})\"), \n",
    "        (\"query(q_colbert)\", \"tensor<bfloat16>(qt{}, x[1024])\"),\n",
    "        (\"query(q_len_colbert)\", \"float\"),\n",
    "    ],\n",
    "    functions=[\n",
    "        Function(\n",
    "            name=\"dense\",\n",
    "            expression=\"cosine_similarity(query(q_dense), attribute(dense_rep),x)\"\n",
    "        ),\n",
    "        Function(\n",
    "            name=\"lexical\",\n",
    "            expression=\"sum(query(q_lexical) * attribute(lexical_rep))\"\n",
    "        ),\n",
    "        Function(\n",
    "            name=\"max_sim\",\n",
    "            expression=\"sum(reduce(sum(query(q_colbert) * attribute(colbert_rep) , x),max, t),qt)/query(q_len_colbert)\"\n",
    "        )\n",
    "    ],\n",
    "    first_phase=FirstPhaseRanking(\n",
    "        expression=\"0.4*dense + 0.2*lexical +  0.4*max_sim\",\n",
    "        rank_score_drop_limit=0.0\n",
    "    ),\n",
    "    match_features=[\"dense\", \"lexical\", \"max_sim\", \"bm25(text)\"]\n",
    ")\n",
    "m_schema.add_rank_profile(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=vespa_application_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_fields = {\n",
    "    \"text\": passage[0],\n",
    "    \"lexical_rep\": {key: float(value) for key, value in passage_embeddings['lexical_weights'][0].items()},\n",
    "    \"dense_rep\":passage_embeddings['dense_vecs'][0].tolist(),\n",
    "    \"colbert_rep\":  {index: passage_embeddings['colbert_vecs'][0][index].tolist() for index in range(passage_embeddings['colbert_vecs'][0].shape[0])}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.io import VespaResponse\n",
    "response: VespaResponse = app.feed_data_point(schema='m', data_id=0, fields=vespa_fields)\n",
    "assert(response.is_successful())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query  = [\"Why is the sky blue?\"]\n",
    "query_embeddings = model.encode(query, return_dense=True, return_sparse=True, return_colbert_vecs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_length = query_embeddings['colbert_vecs'][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fields = {\n",
    "    \"input.query(q_lexical)\": {key: float(value) for key, value in query_embeddings['lexical_weights'][0].items()},\n",
    "    \"input.query(q_dense)\": query_embeddings['dense_vecs'][0].tolist(),\n",
    "    \"input.query(q_colbert)\":  str({index: query_embeddings['colbert_vecs'][0][index].tolist() for index in range(query_embeddings['colbert_vecs'][0].shape[0])}),\n",
    "    \"input.query(q_len_colbert)\": query_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"index:mtest_content/0/cfcd2084234135f700f08abf\",\n",
      "  \"relevance\": 0.24681896577832974,\n",
      "  \"source\": \"mtest_content\",\n",
      "  \"fields\": {\n",
      "    \"matchfeatures\": {\n",
      "      \"bm25(text)\": 0.28768207245178085,\n",
      "      \"dense\": 0.2560008149555224,\n",
      "      \"lexical\": 0.017232894897460938,\n",
      "      \"max_sim\": 0.35243015204157147\n",
      "    },\n",
      "    \"text\": \"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaQueryResponse\n",
    "import json\n",
    "\n",
    "response:VespaQueryResponse = app.query(\n",
    "    yql=\"select id, text from m where userQuery() or ({targetHits:10}nearestNeighbor(dense_rep,q_dense))\",\n",
    "    ranking=\"m3hybrid\",\n",
    "    query=query[0],\n",
    "    body={\n",
    "        **query_fields\n",
    "    }\n",
    ")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.hits[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0173909030854702"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_lexical_matching_score(passage_embeddings['lexical_weights'][0], query_embeddings['lexical_weights'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25596598"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings['dense_vecs'][0] @ passage_embeddings['dense_vecs'][0].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3544)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.colbert_score(query_embeddings['colbert_vecs'][0],passage_embeddings['colbert_vecs'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
