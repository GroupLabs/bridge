{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: requires tesseract (impira/layoutlm-document-qa) & poppler (pdf2image) to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/datasets/pdf_tressl/AddendumDetail-Report-202311230750 (2023-11-23).pdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = \"../../data/datasets/pdf_tressl\"\n",
    "os.listdir(data)[0]\n",
    "\n",
    "PDF_path = f\"{data}/{os.listdir(data)[0]}\"\n",
    "\n",
    "PDF_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded texify model to mps with torch.float16 dtype\n",
      "models loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelthomas/Documents/GitHub/Bridge/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:942: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested: temp/page_1.pdf\n",
      "Ingested: temp/page_2.pdf\n",
      "Ingested: temp/page_3.pdf\n",
      "Ingested: temp/page_4.pdf\n",
      "Ingested: temp/page_5.pdf\n",
      "Ingested: temp/page_6.pdf\n",
      "Ingested: temp/page_7.pdf\n",
      "Ingested: temp/page_8.pdf\n",
      "Ingested: temp/page_9.pdf\n",
      "Ingested: temp/page_10.pdf\n",
      "Ingested: temp/page_11.pdf\n",
      "Ingested: temp/page_12.pdf\n",
      "Ingested: temp/page_13.pdf\n",
      "Ingested: temp/page_14.pdf\n",
      "Ingested: temp/page_15.pdf\n",
      "Ingested: temp/page_16.pdf\n",
      "Ingested: temp/page_17.pdf\n",
      "Ingested: temp/page_18.pdf\n",
      "Ingested: temp/page_19.pdf\n",
      "Ingested: temp/page_20.pdf\n",
      "Ingested: temp/page_21.pdf\n",
      "Ingested: temp/page_22.pdf\n",
      "Ingested: temp/page_23.pdf\n",
      "Ingested: temp/page_24.pdf\n",
      "Ingested: temp/page_25.pdf\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "\n",
    "from marker.convert import convert_single_pdf\n",
    "from marker.models import load_all_models\n",
    "import json\n",
    "\n",
    "fname = PDF_path\n",
    "model_lst = load_all_models()\n",
    "\n",
    "print(\"models loaded\")\n",
    "\n",
    "from vector_store import VectorStore\n",
    "\n",
    "vs = VectorStore()\n",
    "\n",
    "def marker(pdf_path):\n",
    "    full_text, out_meta = convert_single_pdf(pdf_path, model_lst, max_pages=None, parallel_factor=2)\n",
    "\n",
    "    out_path = f'{pdf_path}_marked.md'\n",
    "\n",
    "    with open(out_path, \"w+\", encoding='utf-8') as f:\n",
    "        f.write(full_text)\n",
    "\n",
    "    out_meta_filename = out_path.rsplit(\".\", 1)[0] + \"_meta.json\"\n",
    "    with open(out_meta_filename, \"w+\") as f:\n",
    "        f.write(json.dumps(out_meta, indent=4))\n",
    "\n",
    "    return full_text\n",
    "\n",
    "def split_pdf_into_pages(pdf_path, output_folder):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            writer = PyPDF2.PdfWriter()\n",
    "            writer.add_page(reader.pages[page_num])\n",
    "\n",
    "            output_filename = os.path.join(output_folder, f'page_{page_num + 1}.pdf')\n",
    "            with open(output_filename, 'wb') as output_file:\n",
    "                writer.write(output_file)\n",
    "\n",
    "            marked_text = marker(output_filename)\n",
    "            vs.store_page(marked_text, page_num + 1)\n",
    "            print(f\"Ingested: {output_filename}\")\n",
    "\n",
    "split_pdf_into_pages(PDF_path, 'temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_image(pdf_path):\n",
    "    images = convert_from_path(pdf_path)\n",
    "\n",
    "    # Calculate the total height of all images (assuming they have the same width)\n",
    "    total_height = sum(img.size[1] for img in images)\n",
    "    max_width = max(img.size[0] for img in images)\n",
    "\n",
    "    # Create a new image with the appropriate height and width\n",
    "    combined_image = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "    # Paste the images together\n",
    "    y_offset = 0\n",
    "    for img in images:\n",
    "        combined_image.paste(img, (0, y_offset))\n",
    "        y_offset += img.size[1]\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n",
    "\n",
    "# nlp = pipeline(\n",
    "#     \"document-question-answering\", \n",
    "#     model=\"impira/layoutlm-invoices\"\n",
    "# )\n",
    "\n",
    "# nlp = pipeline(\"document-question-answering\", model=\"naver-clova-ix/donut-base-finetuned-docvqa\")\n",
    "\n",
    "query = \"What is the length used by BRIDGE (LOC 131363) - S00132?\"\n",
    "res_obj = vs.query(query)\n",
    "\n",
    "res_obj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pdf_to_image(f\"temp/page_{res_obj[0][0]}.pdf\")\n",
    "\n",
    "ans = nlp(\n",
    "    img,\n",
    "    query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 km\n"
     ]
    }
   ],
   "source": [
    "print(ans[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9039022922515869, 'answer': '32000', 'start': 427, 'end': 427}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"mistral_paper.png\", \"What is the vocab_size?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
