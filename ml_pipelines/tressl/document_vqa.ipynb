{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: requires tesseract (impira/layoutlm-document-qa) & poppler (pdf2image) to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/datasets/pdf_tressl/AddendumDetail-Report-202311230750 (2023-11-23).pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = \"../../data/datasets/pdf_tressl\"\n",
    "os.listdir(data)[0]\n",
    "\n",
    "PDF_path = f\"{data}/{os.listdir(data)[0]}\"\n",
    "\n",
    "PDF_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'marker.convert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mPyPDF2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_single_pdf\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_all_models\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/noelthomas/Documents/GitHub/Bridge/ml_pipelines/tressl/document_vqa.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'marker.convert'"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "\n",
    "from marker.convert import convert_single_pdf\n",
    "from marker.models import load_all_models\n",
    "import json\n",
    "\n",
    "fname = PDF_path\n",
    "model_lst = load_all_models()\n",
    "\n",
    "print(\"models loaded\")\n",
    "\n",
    "from vector_store import VectorStore\n",
    "\n",
    "vs = VectorStore()\n",
    "\n",
    "def marker(pdf_path):\n",
    "    full_text, out_meta = convert_single_pdf(pdf_path, model_lst, max_pages=None, parallel_factor=2)\n",
    "\n",
    "    out_path = f'{pdf_path}_marked.md'\n",
    "\n",
    "    with open(out_path, \"w+\", encoding='utf-8') as f:\n",
    "        f.write(full_text)\n",
    "\n",
    "    out_meta_filename = out_path.rsplit(\".\", 1)[0] + \"_meta.json\"\n",
    "    with open(out_meta_filename, \"w+\") as f:\n",
    "        f.write(json.dumps(out_meta, indent=4))\n",
    "\n",
    "    return full_text\n",
    "\n",
    "def split_pdf_into_pages(pdf_path, output_folder):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            writer = PyPDF2.PdfWriter()\n",
    "            writer.add_page(reader.pages[page_num])\n",
    "\n",
    "            output_filename = os.path.join(output_folder, f'page_{page_num + 1}.pdf')\n",
    "            with open(output_filename, 'wb') as output_file:\n",
    "                writer.write(output_file)\n",
    "\n",
    "            marked_text = marker(output_filename)\n",
    "            vs.store_page(marked_text, page_num + 1)\n",
    "            print(f\"Ingested: {output_filename}\")\n",
    "\n",
    "split_pdf_into_pages(PDF_path, 'temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_image(pdf_path):\n",
    "    images = convert_from_path(pdf_path)\n",
    "\n",
    "    # Calculate the total height of all images (assuming they have the same width)\n",
    "    total_height = sum(img.size[1] for img in images)\n",
    "    max_width = max(img.size[0] for img in images)\n",
    "\n",
    "    # Create a new image with the appropriate height and width\n",
    "    combined_image = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "    # Paste the images together\n",
    "    y_offset = 0\n",
    "    for img in images:\n",
    "        combined_image.paste(img, (0, y_offset))\n",
    "        y_offset += img.size[1]\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n",
    "\n",
    "# nlp = pipeline(\n",
    "#     \"document-question-answering\", \n",
    "#     model=\"impira/layoutlm-invoices\"\n",
    "# )\n",
    "\n",
    "# nlp = pipeline(\"document-question-answering\", model=\"naver-clova-ix/donut-base-finetuned-docvqa\")\n",
    "\n",
    "query = \"What is the length used by BRIDGE (LOC 131363) - S00132?\"\n",
    "res_obj = vs.query(query)\n",
    "\n",
    "res_obj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pdf_to_image(f\"temp/page_{res_obj[0][0]}.pdf\")\n",
    "\n",
    "ans = nlp(\n",
    "    img,\n",
    "    query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 km\n"
     ]
    }
   ],
   "source": [
    "print(ans[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9039022922515869, 'answer': '32000', 'start': 427, 'end': 427}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"mistral_paper.png\", \"What is the vocab_size?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
